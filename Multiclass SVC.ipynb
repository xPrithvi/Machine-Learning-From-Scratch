{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7f681c",
   "metadata": {},
   "source": [
    "# Multi-Class SVC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd598da4",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In its most basic form SVC is a binary classifier. However, many binary classification are only a subset of the typical classification problems encountered in practice. It is easy to generalise the base SVC model into a multi-class classifier. There are two common approaches to this: OvO (One-vs-One) and OvR (One-vs-the-rest). Let us dicuss these methods from a high-level overview, \n",
    "\n",
    "- **OvR**: OvR is short for _\"One-vs-the-rest\"_. In this approach, a binary classifier is made for each class label. Let us say that we have $M$ of classes, in OvR we create $M$ number of binary classifiers for each class label. When training each classifier, we re-label our data points so that positive class $1$ belongs to our choosen class $k$ and our negative class $0$ includes data points of all other classes. Mathematically,\n",
    "\n",
    "$$\n",
    "y_i^{(k)} = \\begin{cases} +1, & y_i = k, \\\\ 0, & y_i \\neq k. \\end{cases}\n",
    "$$\n",
    "\n",
    "And so each SVM is trained to classify $y_i = k$ from $y_i \\neq k$\n",
    "\n",
    "- **OvO**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55dc7d1",
   "metadata": {},
   "source": [
    "### OvR Implementation\n",
    "\n",
    "In OvR, the final class prediction for a given sample $X_i$ is determined from the BaseSVC whose decision function $f_k(X_i)$ is the largest. Note that $k$ denotes the $k$-th class label. We can imagine $f_k(X_i) = X_iW^T_{(k)} + b_{(k)}$ as a measure of how strongly a sample belongs to the class $k$. Mathematically,\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\text{argmax}_k \\quad f_k(X_i)\n",
    "$$\n",
    "\n",
    "where $\\hat{y}$ is our predicted class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17858d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.BaseSVM import BaseSVC\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "class SVC():\n",
    "    \"\"\"This is the class for the support vector classifier with multi-class support using a OvR approach.\"\"\"\n",
    "\n",
    "    def __init__(self, C=1):\n",
    "        \"\"\"Constructor method.\"\"\"\n",
    "\n",
    "        # Hyperparameters,\n",
    "        self.C = C\n",
    "\n",
    "        # Class attributes,\n",
    "        self.class_labels, self.n_labels = None, None\n",
    "        self.model_score = None\n",
    "\n",
    "        # Stores all base SVC models,\n",
    "        self.base_clfs = []\n",
    "\n",
    "    def fit(self, X, y, n_jobs=-1):\n",
    "        \"\"\"DocString to be filled out.\"\"\"\n",
    "\n",
    "        # Extracting class labels,\n",
    "        self.class_labels = np.unique(y)\n",
    "        self.n_labels = len(self.class_labels)\n",
    "\n",
    "        # Fitting BaseSVCs in parallel,\n",
    "        self.base_clfs = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(self._fit_baseSVC)(X, y, class_label) for class_label in self.class_labels\n",
    "            )\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"DocString to be filled out.\"\"\"\n",
    "\n",
    "        # Creating prediction matrix,\n",
    "        preds_matrix = np.zeros(shape=(self.n_labels, X.shape[0]))\n",
    "        for i, clf in enumerate(self.base_clfs):\n",
    "            preds = clf._decision_function(X)\n",
    "            preds_matrix[i] = preds\n",
    "\n",
    "        # Returning predictions,\n",
    "        preds = np.zeros(shape=X.shape[0], dtype=int)\n",
    "\n",
    "        for i, base_preds in enumerate(preds_matrix.T):\n",
    "            label_pred = np.argmax(base_preds)\n",
    "            preds[i] = label_pred\n",
    "        \n",
    "        return preds\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Returns the classification accuracy on the supplied dataset.\"\"\"\n",
    "\n",
    "        # Calculating model predictions,\n",
    "        y_preds = self.predict(X)\n",
    "\n",
    "        # Computing classification accuracy,\n",
    "        self.model_score = np.mean(y_preds == y)\n",
    "\n",
    "        return self.model_score\n",
    "\n",
    "    def _fit_baseSVC(self, X, y, class_label):\n",
    "        \"\"\"Helper function for fitting a BaseSVC model.\"\"\"\n",
    "\n",
    "        # Finding class labels,\n",
    "        class_idxs = np.where(y == class_label)[0]\n",
    "        class_comp_idxs = np.where(y != class_label)[0] # <-- The compliment.\n",
    "\n",
    "        # Re-labeling class labels,\n",
    "        X_class, y_class = X[class_idxs], np.ones(shape=len(class_idxs))\n",
    "        X_class_comp, y_class_comp = X[class_comp_idxs], np.zeros(shape=len(class_comp_idxs))\n",
    "\n",
    "        # Combining and splitting,\n",
    "        X_new = np.concatenate((X_class, X_class_comp), axis=0)\n",
    "        y_new = np.concatenate((y_class, y_class_comp), axis=0)\n",
    "\n",
    "        # Training BaseSVM model,\n",
    "        clf = BaseSVC(C=self.C)\n",
    "        clf.fit(X_new, y_new)\n",
    "\n",
    "        return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3c00a",
   "metadata": {},
   "source": [
    "### Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77b5af69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset,\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Creating data split,\n",
    "wine_dataset = load_wine()\n",
    "X, y = wine_dataset[\"data\"], wine_dataset[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Training model,\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
